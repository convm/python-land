{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stanfordnlp.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stanfordnlp.download('zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = stanfordnlp.Pipeline(processors=\"tokenize,mwt,lemma,pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"\"\"The prospects for Britain’s orderly withdrawal from the European Union on March 29 have receded further, even as MPs rallied to stop a no-deal scenario. An amendment to the draft bill on the termination of London’s membership of the bloc obliges Prime Minister Theresa May to renegotiate her withdrawal agreement with Brussels. A Tory backbencher’s proposal calls on the government to come up with alternatives to the Irish backstop, a central tenet of the deal Britain agreed with the rest of the EU.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc.sentences[0].print_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#extract lemma\n",
    "def extract_lemma(doc):\n",
    "    parsed_text = {'word':[], 'lemma':[]}\n",
    "    for sent in doc.sentences:\n",
    "        for wrd in sent.words:\n",
    "            #extract text and lemma\n",
    "            parsed_text['word'].append(wrd.text)\n",
    "            parsed_text['lemma'].append(wrd.lemma)\n",
    "    #return a dataframe\n",
    "    return pd.DataFrame(parsed_text)\n",
    "\n",
    "#call the function on doc\n",
    "extract_lemma(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dictionary that contains pos tags and their explanations\n",
    "pos_dict = {\n",
    "'CC': 'coordinating conjunction','CD': 'cardinal digit','DT': 'determiner',\n",
    "'EX': 'existential there (like: \\\"there is\\\" ... think of it like \\\"there exists\\\")',\n",
    "'FW': 'foreign word','IN':  'preposition/subordinating conjunction','JJ': 'adjective \\'big\\'',\n",
    "'JJR': 'adjective, comparative \\'bigger\\'','JJS': 'adjective, superlative \\'biggest\\'',\n",
    "'LS': 'list marker 1)','MD': 'modal could, will','NN': 'noun, singular \\'desk\\'',\n",
    "'NNS': 'noun plural \\'desks\\'','NNP': 'proper noun, singular \\'Harrison\\'',\n",
    "'NNPS': 'proper noun, plural \\'Americans\\'','PDT': 'predeterminer \\'all the kids\\'',\n",
    "'POS': 'possessive ending parent\\'s','PRP': 'personal pronoun I, he, she',\n",
    "'PRP$': 'possessive pronoun my, his, hers','RB': 'adverb very, silently,',\n",
    "'RBR': 'adverb, comparative better','RBS': 'adverb, superlative best',\n",
    "'RP': 'particle give up','TO': 'to go \\'to\\' the store.','UH': 'interjection errrrrrrrm',\n",
    "'VB': 'verb, base form take','VBD': 'verb, past tense took',\n",
    "'VBG': 'verb, gerund/present participle taking','VBN': 'verb, past participle taken',\n",
    "'VBP': 'verb, sing. present, non-3d take','VBZ': 'verb, 3rd person sing. present takes',\n",
    "'WDT': 'wh-determiner which','WP': 'wh-pronoun who, what','WP$': 'possessive wh-pronoun whose',\n",
    "'WRB': 'wh-abverb where, when','QF' : 'quantifier, bahut, thoda, kam (Hindi)','VM' : 'main verb',\n",
    "'PSP' : 'postposition, common in indian langs','DEM' : 'demonstrative, common in indian langs'\n",
    "}\n",
    "\n",
    "#extract parts of speech\n",
    "def extract_pos(doc):\n",
    "    parsed_text = {'word':[], 'pos':[], 'exp':[]}\n",
    "    for sent in doc.sentences:\n",
    "        for wrd in sent.words:\n",
    "            if wrd.pos in pos_dict.keys():\n",
    "                pos_exp = pos_dict[wrd.pos]\n",
    "            else:\n",
    "                pos_exp = 'NA'\n",
    "            parsed_text['word'].append(wrd.text)\n",
    "            parsed_text['pos'].append(wrd.pos)\n",
    "            parsed_text['exp'].append(pos_exp)\n",
    "    #return a dataframe of pos and text\n",
    "    return pd.DataFrame(parsed_text)\n",
    "\n",
    "#extract pos\n",
    "extract_pos(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\wilson\\\\stanfordnlp_resources\\\\zh_gsd_models\\\\zh_gsd_tokenizer.pt', 'lang': 'zh', 'shorthand': 'zh_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\wilson\\\\stanfordnlp_resources\\\\zh_gsd_models\\\\zh_gsd_tagger.pt', 'pretrain_path': 'C:\\\\Users\\\\wilson\\\\stanfordnlp_resources\\\\zh_gsd_models\\\\zh_gsd.pretrain.pt', 'lang': 'zh', 'shorthand': 'zh_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\wilson\\\\stanfordnlp_resources\\\\zh_gsd_models\\\\zh_gsd_lemmatizer.pt', 'lang': 'zh', 'shorthand': 'zh_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline(lang='zh', processors='tokenize,mwt,pos,lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "174\n",
      "348\n",
      "522\n",
      "696\n",
      "870\n",
      "1044\n",
      "1218\n",
      "1392\n",
      "1566\n",
      "1740\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 0\n",
    "for i in range(10):\n",
    "    doc = nlp(\"開工日期 : 01/02/2019 估價 ($) 完工日期  1,452.00 21/02/2019  1. 請根據以下指示, 安排維修工作  ~~~~~~~~~~~~~~~~~~~~~~  1. 全層 休憩設備 自訂維修項目$1200(.) 1 no.  附加備註: 因颱風山竹关系，令花槽內的大樹幹扯起，而連着樹底地磚的石矢受損，  現需出代工代為清理石矢及雜物。  Item : 170010 General worker and labourer             代工工時，由上午8時至晚上6時共8小時。『本項目完』  專責人員 : 姓名 SIT Man-wai 職位 : ACW/HNI13  批核人員 : 姓名 SIT Man-wai 職位 : ACW/HNI13  出單日期 : 30/01/2019  通知完工 完工備註 :  茲証明此小型維修工程已於今天完工  簽署 : 姓名 : 日期 :  HD578 (TMS)\")\n",
    "    print(n)\n",
    "    for s in doc.sentences:\n",
    "        for w in s.words:\n",
    "            if (w.upos not in ['PUNCT','SYM','NUM']):\n",
    "                n = n + 1\n",
    "                \n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開工\n",
      "日期\n",
      "估價\n",
      "完工\n",
      "日期\n",
      "請\n",
      "根據\n",
      "以下\n",
      "指示\n",
      "安排\n",
      "維修\n",
      "工作\n",
      "全層\n",
      "休憩\n",
      "設備\n",
      "自訂\n",
      "維修\n",
      "項目\n",
      "1no\n",
      "附加\n",
      "備註\n",
      "因\n",
      "颱風\n",
      "山竹\n",
      "关系\n",
      "，令\n",
      "花槽\n",
      "內\n",
      "的\n",
      "大樹\n",
      "幹\n",
      "扯\n",
      "起\n",
      "而\n",
      "連着\n",
      "樹\n",
      "底\n",
      "地磚\n",
      "的\n",
      "石矢\n",
      "受損\n",
      "現\n",
      "需\n",
      "出代\n",
      "工代\n",
      "為\n",
      "清理\n",
      "石矢\n",
      "及\n",
      "雜物\n",
      "Item\n",
      "General\n",
      "worker\n",
      "and\n",
      "labourer\n",
      "代工工\n",
      "時，\n",
      "由\n",
      "上午\n",
      "時\n",
      "至\n",
      "晚上\n",
      "時\n",
      "共\n",
      "小時\n",
      "本\n",
      "項目\n",
      "完\n",
      "專責\n",
      "人員\n",
      "姓名\n",
      "SIT\n",
      "Man-wai\n",
      "職位\n",
      "ACW\n",
      "HNI13\n",
      "批\n",
      "核\n",
      "人員\n",
      "姓名\n",
      "SIT\n",
      "Man-wai\n",
      "職位\n",
      "ACW\n",
      "HNI13\n",
      "出\n",
      "日期\n",
      "通\n",
      "知\n",
      "完工\n",
      "完工\n",
      "備註\n",
      "茲\n",
      "証明\n",
      "此\n",
      "小型\n",
      "維修\n",
      "工程\n",
      "已\n",
      "於\n",
      "今天\n",
      "完工\n",
      "簽署\n",
      "姓名\n",
      "日期\n",
      "HD578\n",
      "TMS\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"開工日期 : 01/02/2019 估價 ($) 完工日期  1,452.00 21/02/2019  1. 請根據以下指示, 安排維修工作  ~~~~~~~~~~~~~~~~~~~~~~  1. 全層 休憩設備 自訂維修項目$1200(.) 1 no.  附加備註: 因颱風山竹关系，令花槽內的大樹幹扯起，而連着樹底地磚的石矢受損，  現需出代工代為清理石矢及雜物。  Item : 170010 General worker and labourer             代工工時，由上午8時至晚上6時共8小時。『本項目完』  專責人員 : 姓名 SIT Man-wai 職位 : ACW/HNI13  批核人員 : 姓名 SIT Man-wai 職位 : ACW/HNI13  出單日期 : 30/01/2019  通知完工 完工備註 :  茲証明此小型維修工程已於今天完工  簽署 : 姓名 : 日期 :  HD578 (TMS)\")\n",
    "for s in doc.sentences:\n",
    "    for w in s.words:\n",
    "        if (w.upos not in ['PUNCT','SYM','NUM']):\n",
    "            print(w.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
